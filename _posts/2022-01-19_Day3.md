---
title:  "[부스트캠프 AI] Day3"
excerpt: "1주차 학습기록"

categories:
  - ['Boostcamp AI', 'Python']
tags:
  - [Boostcamp AI]

published: true
toc: true
toc_sticky: true
 
date: 2022-01-19
last_modified_at: 2022-01-23
---

# **[Python]**
## **3-1. Python Data Structure**
- Stack(LIFO), Queue(FIFO)
- tuple : 값 변경이 불가능한 리스트, 데이터 변경X 경우   
    * 값이 하나인 tuple은 ‘,’ 붙여야 튜플로 인식
- set : 중복이 불가능한 자료, 순서X
- dictionary(Hash Table) - key:value
- Collection Module [collections]
    - deque : Stack, Queue 지원하는 모듈
    - list에 비해 효율적인 저장방식 지원
    - Counter : data element들의 갯수를 dict 형태로 반환
    - OrderedDict : 3.6부터 기본 지원
    - defaultdict : Dict의 값에 기본 값을 지정, 신규값 생성시 사용하는 방법
        > **defaultdict 이용 예시**
        -  'String[] strs' 값이 주어지면 Anagrams 을 이루는 단어들을 한 리스트로 묶어서 출력하는 문제    
        - Anagrams : 문자의 순서를 바꾸어서 만들 수 있는 다른 문자
        
        ```python
        #https://leetcode.com/problems/group-anagrams/
        
        from collections import defaultdict
        
        def groupAnagrams(strs):
            words = defaultdict(list)
            result = []
            
            for word in strs:
                temp = sorted(list(word))
                temp_word = ''.join(temp)
                
                        # defaultdict로 기본 값 리스트로 설정 -> 없어도 자동으로 값 채워줌
                words[temp_word] += [word]
                    
            for key in words.keys():
                result.append(sorted(words.get(key)))
                
            result = sorted(result, key=len)
            return result, words
        
        strs = ["eat","tea","tan","ate","nat","bat"]
        groupAnagrams(strs)
        ```
            
    - namedtuple : tuple 형태로 Data 구조체를 저장 (data의 variable을 사전에 지정해서 저장)   
<br></br>
## **3-2. Pythonic code**
- split & join
- list comprehension* : 일반적으로 for + append보다 속도 빠름
- enumerate & zip
- lambda & map & reduce
- generator
- asterisk   
<br></br>
## **4-1. Python Object Oriented Programming**
>    💡  OOP : 객체 개념을 프로그램으로 표현   
    - 속성은 변수(variable), 행동은 함수(method)로 표현   
    - Class : 설계도, instance : 실제 구현체   

- Python naming rule : snake_case, CamelCase
- Attribute 추가 : __ init__(객체 초기화 함수), self(추가해야만 class 함수로 인정됨)
- Notebook : 사용자는 Note에 뭔가를 적을 수 있음. Content가 있고, 내용 제거 가능
- Inheritance(상속) : 부모클래스로부터 속성과 Method를 물려받은 자식 클래스를 생성하는 것
- Polymorphism(다형성) : 같은 이름 메소드의 내부 로직을 다르게 작성
- Visibility(가시성) : 객체 정보를 볼 수 있는 레벨 조절 → 누구나 객체 안에 모든 변수를 볼 필요가 없음   

    >    💡 Encapsulation(캡슐화, 정보은닉)   
        - Class 설계할 때, 클래스 간 간섭/정보공유의 최소화   

    - decorate
        - First-class objects(일등함수) : 변수나 데이터 구조에 할당이 가능한 객체, 파라미터로 전달 가능 + 리턴 값으로 사용
        - Inner function : 함수 내에 또 다른 함수가 존재
        - closures : inner function을 return 값으로 반환   
<br></br>
## **4-2. Module and Project**
### **Module**    
&nbsp;: 프로그램을 모듈화 시키면 다른 프로그램이 사용하기 쉬움
- 같은 폴더에 Module에 해당하는 .py 파일 & 사용하는 .py 저장 → import로 호출
- namespace : 필요한 내용만 호출 가능
    - Alias 설정
    
    ```python
    import numpy as np
    ```
    
    - 모듈에서 특정 함수 또는 클래스만 호출
    
    ```python
    from itertools import Combinations
    ```
    
    - 모듈에서 모든 함수 또는 클래스 호출
    
    ```python
    from sklearn.metrics import *
    ```
        
    - Built-in Model : random, time, urllib.request    
&nbsp;
### Package
: 하나의 대형 프로젝트를 만드는 코드의 묶음, 다양한 모듈들의 합(폴더로 연결)   

> - Package 만들기   
    1) 기능을 세부적으로 나눠 폴더 만듦   
    2) 각 폴더별로 필요한 모듈 구현         
    3) 1차 Test (python shell에서)   
    4) 폴더별로 __ init__.py 구성하기    
    5) __ main__.py 파일 만들기   
     * __ init__.py : 현재 폴더가 패키지임을 알리는 초기화 스크립트     하위 폴더와 .py파일(모듈)을 모두 포함    

&nbsp;
### **Virtual Environment**
: 프로젝트 진행 시 필요한 패키지만 설치하는 환경
- 다양한 패키지 관리 도구를 사용
- virtualenv (+pip): 가장 대표적인 가상환경 관리 도구 (레퍼런스+패키지 개수)
- conda : 상용 가상환경 도구 → windows에서 설치 장점
    > Windows : conda / linux, mac : conda or pip

<br></br>
<br></br>
# **[AI Math]**
## **5. 딥러닝 학습방법 이해하기**
### **신경망을 수식으로 분해해보기**
&nbsp;  ⇒ 비선형모델인 신경망(neural network)
- 행벡터 $O_i$는 데이터 $X_i$와 가중치 행렬 $W$사이의 행렬곱과 절편 $b$벡터의 합으로 표현
    
    <!-- ![스크린샷 2022-01-20 오전 1.23.37.png](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/0d957a0e-8edf-4525-bedd-5ae64c56cfa6/스크린샷_2022-01-20_오전_1.23.37.png) -->
    
    - $X_i$ : 데이터 , $W$: 가중치 행렬(다른 데이터 공간으로 보내줌), $b$ : y절편(각 행이 같음)
    - 출력 차원 : n x p   ((n x d) x (d x p))
- softmax
    <!-- ![스크린샷 2022-01-20 오전 1.25.10.png](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/37b738f6-f3d9-4741-a713-55216381baa3/스크린샷_2022-01-20_오전_1.25.10.png) -->
    - 모델의 출력을 확률로 해석할 수 있게 변환해주는 연산
    - 출력 벡터 o에 softmax 함수를 합성하면 확률벡터가 되므로 ‘특정 클래스 k에 속할 확률’로 해석 가능
    - 분류 문제를 풀 때 선형모델과 소프트맥스 함수를 결합하여 예측
    $softmax(o) = softmax(W_x+b)$
- 신경망 : 선형모델과 활성함수(activation fuction)를 합성한 함수   
&nbsp;
### **활성함수(activation function)**
- 활성함수를 쓰지 않으면 딥러닝은 선형모델과 차이가 없음
- sigmoid, tanh, ReLU (나중에 자료 추가)   
&nbsp;
### **다층 퍼셉트론(MLP)**
: 신경망이 여러층 합성된 함수
- MLP의 파라미터는 L개의 가중치 행렬 $W^1$~$W^n$과 $b^1$~$b^n$으로 이루어져 있음
- $l = 1, ..., L$까지 순차적인 신경망 계산 ⇒ 순전파 (학습X 주어진 데이터 → 출력으로 내뱉는 것)
- 층을 여러개 쌓는 이유?
    - 층이 깊을수록 목적함수를 근사하는데 필요한 뉴런(노드)의 숫자가 빠르게 줄어들어 효율적인 학습 가능
    - 층이 얇으면 필요한 뉴런의 숫자가 기하급수적으로 늘어나서 넓은 신경망이 되어야함
    - 층이 깊으면 복잡한 문제 풀 수 있지만 최적화 어려움   
&nbsp;
### **딥러닝 학습 원리 : 역전파(backpropagation)**
- 딥러닝은 역전파 알고리즘을 이용하여 각 층에 사용된 파라미터 $\{W^{(l)}, b^{(l)}\}^L_{l=1}$를 학습
- 손실함수를 $l$라 했을 때 $dl/dw^{(l)}$ 정보 계산에 사용
- $l = L, ..., 1$ 순서로 연쇄법칙을 통해 그래디언트 벡터를 전달
- 미분 한번에 계산X, 순차적 계산 (윗층부터 역순으로)   
&nbsp;
### **Quiz 관련 추가 자료**
- tanh 미분 정리
<!-- ![스크린샷 2022-01-19 오후 5.13.53.png](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/dcd7c34d-c6c8-4496-b84f-9d25055cada4/스크린샷_2022-01-19_오후_5.13.53.png) -->

```python
import numpy as np

def tanh(x, diff=False):
    if diff:
    return (1+tanh(x))*(1-tanh(x))
    else:
    return np.tanh(x)
```

<!-- - $z = (k+3)^3, k = (x+y)^2$ → $dz/dx ?$ -->
<!-- ![스크린샷 2022-01-20 오전 1.17.36.png](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/ecdd9068-468a-4315-9275-ee55be1ae85d/스크린샷_2022-01-20_오전_1.17.36.png) -->