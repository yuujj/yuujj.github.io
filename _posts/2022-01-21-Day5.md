---
layout : post
title:  "[부스트캠프 AI] Day5"
excerpt: "1주차 학습기록"

categories: ["Boostcamp AI", "Python"]
tags: ["Boostcamp AI"]

published: true
toc: true
toc_sticky: true
 
date: 2022-01-21
last_modified_at: 2022-01-29
use_math: true
--- 

# **[Python]**
---
## **5-1. File / Exception / Log Handling**
### **Exception**
- 분류
    - 예상 가능한 예외 : 개발자가 명시적으로 정의
        *(ex. 사용자의 잘못된 입력, 파일 없음)*
    - 예상 불가능한 예외 : 인터프리터 과정에서 발생하는 예외 → 발생시 인터프리터가 자동 호출
        *(ex. 개발자 실수)*
- 예외처리 [try~except]  **학습자료와 다른 예시*

```python
try:
    a = [1,2]
    print(a[3])
    4/0
except ZeroDivisionError:
    print("0으로 나눌 수 없습니다.")
except IndexError:
    print("인덱싱 할 수 없습니다.")
# else: -> 예외 발생X 시 동작하는 코드
# finally: -> 예외 발생 여부와 관련X 실행 
```

- 종류 - IndexError, NameError, ZeroDivisionError, ValueError, FileNotFoundError
- 구문
    - try ~ except / try ~ except ~ else / try ~ except ~ finally
    - raise <exception type> exception_info → 강제로 예외 발생
    - assert 예외조건 → 조건에 만족X 경우 예외 발생   

<br>
### **File**
- 파일의 기본 체계 - 파일(정보 저장하는 논리적 단위, 확장자로 식별) / 디렉토리(폴더)
- 종류
    - Binary 파일 : 컴퓨터만 이해 가능한 **이진법 형식** *(ex. 엑셀, 워드 파일 등)*
    - Text 파일 : 사람도 이해 가능한 **문자열 형식** (ex. HTML, Python 코드 파일 등)
- I/O - ‘open’ 사용 [mode : r(읽기), w(쓰기), a(추가)]
- read() : 같은 폴더에 있을 경우, 파일 내용을 문자열로 반환 / readlines() : 한줄씩 읽어 list type으로 반환
- Log 파일 생성 - 디렉토리가 있는지, 파일 있는지 확인 후
- Pickle - 파이썬 객체를 영속화(persistence) 하는 bulit-in 객체, 활용 다양함 
    → 데이터 크기 클 때 pickle로 저장하면 크기가 작아져서 많이 사용했음   

<br>
### **Logging**
프로그램 실행동안 일어나는 정보 기록 (유저 접근, Exception, 특정 함수 사용 등)

- Colsole 창에만 남는 기록은 분석시 사용 불가
- 레벨별(개발, 운영)으로 기록 / 모듈별 별도
- logging 모듈 사용 →  level : debug > info > warning > error > critical   

<br>
### **프로그램 실행 설정**
- configparser - file에 실행 설정 저장 
                        (Section, Key, Value 값 형태 설정파일, Dict Type으로 호출 후 사용)
- argparser - 프로그램 실행시 Setting 정보 저장 (Command-Line Option)   

<br>

---
## **5-2. data handling**
### **CSV**
- csv 객체 활용 
[delimiter(글자나눔), lineterminator(줄바꿈), quotechar(문자열 둘러싸는 신호 문자), quoting(데이터 나누는 기준이 quotechar에 의해 둘러싸인 레벨)]   

<br>
### **Web : 요청 → 처리 → 응답 → 렌더링**
- HTML(Hyper Text Markup Language)
    - 정규식(regular expression) : 복잡한 문자열 패턴을 정의하는 문자 표현 공식   
    → 정규식 연습장 “[http://www.regexr.com/](http://www.regexr.com)”
    - XML : 데이터의 구조와 의미를 설명하는 TAG를 사용하여 표시하는 언어
        - TAG와 TAG 사이에 값이 표시, 구조적인 정보 표현 가능
        - 스키마, DTD 등으로 메타정보 표현
        - 컴퓨터간에 정보를 주고받기 매우 유용한 저장방식으로 쓰임
        - parsing : beautifulsoup으로 파싱
        
    - JSON : Java Script의 데이터 객체 표현 방식   
        - 간결성(이해 편함), 데이터 용량 적고 Code로의 전환 쉬움   
        - key:value 쌍으로 데이터 표시   
         각 사이트마다 Developer API 활용법 찾아 사용

<br>

---
## **6. numpy**
### **numpy**
일반 List에 비해 빠르고, 메모리 효율적, 반복문X 데이터 배열에 대한 처리 지원. Matrix, Vector와 같은 Array 연산의 사실상의 표준
- ndarray : `np.array` 함수 활용, 배열 생성 
    (list와 차이 : dynamic typing not supported - 다양한 타입 넣을 수 X)
- array creation : `.shape` (dimension 구성) / `.dtype` (데이터 타입)
- array shape
0(Rank) : scalar → 1 : vector → 2 : matrix → 3 : 3-tensor → n : n-tensor
- reshape() : element의 개수는 동일, shape 크기 변경 
    *`reshape(-1, n)` :  전체 element size를 기반으로 개수 선정
- flatten() : 다차원 array → 1차원   

<br>
### **indexing & slicing**
- 2차원 배열에서 [0(row), 0(col)] 지원    **list는 [0][0]만 가능*
- 행&열 부분을 나눠서 slicing 가능            **list는 불가능*   

<br>
### **creation function**
- `np.arange()` : array의 범위를 지정, 지정한 값의 배열 추출
- `np.zeros(shape, dtype, order)` : 0으로 가득찬 ndarray 생성
- `np.ones(shape, dtype, order)` : 1로 가득찬 ndarray 생성
- `np.empty()` : shape만 주어지고 비어있는 ndarray(메모리 초기화X)
- `np.identitly(n, dtype)` : 단위행렬 생성
- `np.eye()` : 대각선이 1인 행렬, 시작 index 변경 가능
- `np.diag()` : 대각 행렬의 값을 추출
- `np.random.분포종류()` : 데이터 분포에 따른 sampling으로 array 생성   

<br>
### **operation functions**
- sum/ axis / mean / std ...
- vstack / hstack : numpy array를 합치는 함수 (가로, 세로)
- np.concatenate() : numpy array를 합치는 함수 (가로, 세로)   

<br>
### **array operations**
- +, -, *(array간 shape이 같을 때)
- `.dot()` : Matrix의 기본연산 (행렬곱)
- `.transpose()` :  전치행렬
- `np.argmax()` , `np.argmin()` : array내 최대값 또는 최소값의 index 반환   

<br>
### **numpy data i/o**
- `np.loadtxt()` / `np.savetxt()`  

<br>

---
## **7-1. Pandas_1**
- Series / DataFrame - loc(index 이름), iloc(index number)
→ series - index 기준으로 연산 수행(없으면 NaN) / DataFrame - column, index 모두 고려
- lambda, map, apply
    - series type에도 map 사용 가능, function 대신 dict, sequence형 등으로 자료형 대체 가능
    - bulit-in : describe, unique, sum, isnull, sort_values, corr, cov   

<br>

---
## **7-2. Pandas_2**
### **Groupby**
 split → apply → combine 과정을 거쳐 연산
- Hierarchical index
    : 두 개의 column으로 groupby 할 경우 index가 두 개 생성
    - `unstack()` : group으로 묶인 데이터 → matrix 형태
    - `swaplevel()` : index level 변경
    - 인덱스 기준으로 기본연산 수행 가능
- grouped
    : Groupby에 의해 Split된 상태 추출 가능
    - `.get_group()` : 특정 key 값을 가진 그룹의 정보만 추출 가능
    - aggregation() or agg() / transformation() - 변환시 / filtration() - 조건 검색
- Pivot table & Crosstab
    - Pivot table : column에 추가로 labeling 값 추가, value에 numeric type 값을 aggregation하는 형태
    - Crosstab : 특히 두 칼럼의 교차 빈도, 비율, 덧셈 등을 구할 때 사용, Pivot table의 특수한 형태
- merge & concat
    - join method : INNER JOIN(교집합), FULLJOIN(합집합), LEFT & RIGHT JOIN
- persistence
    - DB connection : Data loading 시 db connection 기능 제공 `import sqlite3`
    - XLS persistence 
    :  df의 엑셀 추출 코드. xls 엔진으로 openpyxls 또는 xlsxwrite 사용   
        `wt = pd.ExcelWriter()` → `df.to_excel(wf)`
    - Pickle persistence   
        `.to_pickle()`, .`read_pickle()`   

<br>
<br>

# **[AI Math]**
---
## **10. RNN 첫걸음**
### **시퀀스 데이터 이해하기**
 **시퀀스(sequence) 데이터** : 소리, 문자열, 주가 등의 데이터
- 독립동등분포(i.i.d) 가정 잘 위배 → 순서 바꾸거나 과거 정보에 손실 발생하는 경우 확률분포도 바뀜   

<br>
### **시퀀스 데이터 다루기**
- 조건부확률(베이즈법칙) 이용 → 이전 시퀀스의 정보를 가지고 앞으로 발생할 데이터의 확률분포 다루기 위함
- 시퀀스 데이터 분석시 모든 과거 정보들이 필요한 것은 X
- 길이가 가변적인 데이터를 다룰 수 있는 모델
  → 조건부에 들어가는 데이터 가변적
    - AR($\tau$) 자귀회귀모델(Autoregressive Model) : 고정된 길이 $\tau$만큼의 시퀀스만 사용하는 경우   
       **$\tau$ : 하이퍼 파라미터 - 사전 지식 필요, 문제에 따라* $\tau$ 바뀔 수 있음
    - 잠재 AR 모델 : 이전 정보를 제외한 나머지 정보를 $H_t$라는 잠재변수로 인코딩해서 활용
- 장점
    1. 과거 모든 데이터 활용
    2. 가변적 데이터 길이 → $\tau$, $H_t$라는 고정된 데이터 길이로 바꿀 수 있음
- 문제점
    - 과거의 데이터를 어떻게 잠재변수로 인코딩? ⇒ 해결 위해 RNN 등장   

<br>
### **RNN(Recurrent Neural Network) 이해하기**
&nbsp; 가장 기본적인 RNN 모형 → MLP와 유사한 모양   


<br>

<img width="646" alt="스크린샷 2022-01-21 오전 11 53 06" src="https://user-images.githubusercontent.com/81269342/150669240-ff9ae149-8b9c-422d-9414-36c2674afbc9.png">
<center>[ ▲ MLP와 유사한 모양의 모델 ]</center> 

<br>
   ⇒  기본적인 MLP 모델로는 과거의 정보를 다룰 수 없음 → 입력행렬이 t번째만 있기 때문   
<br>

<img width="742" alt="스크린샷 2022-01-21 오전 11 55 10" src="https://user-images.githubusercontent.com/81269342/150669265-3d7e7ca4-6b25-4abd-b932-7f9ccdc711e2.png">
<center>[ ▲ 잠재변수 인코딩하는 모델 ]</center> 
<br>

- 모델의 특징
    - 잠재변수인 $H_t$를 복제 → 다음 순서의 잠재변수 인코딩에 활용
    - RNN 모델링 : 이전 순서의 잠재변수 + 현재의 입력
    - RNN의 역전파 : 잠재변수의 연결그래프에 따라 순차적으로 계산
- BPTT(Backpropagation Through Time)
    - 가중치행렬의 미분을 계산 → 미분의 곱으로 이루어진 항 계산됨
    - 시퀀스 길이가 길어지는 경우 BPTT를 통한 역전파 알고리즘의 계산이 불안정해짐 → 기울기 소실문제   

<br>
### **기울기 소실의 해결책**
&nbsp; truncated BPTT : 시퀀스 길이가 길어지는 경우 BPTT는 기울기 소실의 문제가 생김 → 길이를 끊는 것 필요
- 기울기 소실의 문제 해결을 위해 등장한 네트워크 ⇒ LSTM, GRU