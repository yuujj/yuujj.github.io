---
layout : post
title:  "[부스트캠프 AI] Day7"
excerpt: "2주차 학습기록"

categories: ["Boostcamp AI", "Python", "PyTorch"]
tags: ["Boostcamp AI"]

published: true
toc: true
toc_sticky: true
 
date: 2022-01-25
last_modified_at: 2022-01-30
use_math: true
---

# <b>[PyTorch]</b>
---

## **PyTorch 프로젝트 구조 이해하기**

### **PyTorch Project Template Overview**

**Jupyter**    
[장점] - 개발 초기 단계에서는 대화식 개발 과정이 유리 (디버깅 과정)   
[단점] - 배포 및 공유 단계에서 공유 어려움 (재현 가능성의 한계)   
⇒ DL 코드도 하나의 프로그램으로, 개발 용이성 확보 & 유지보수 향상 필요
⇒ 다양한 PyTorch Template이 있으니 활용

<br>

---


## **AutoGrad & Optimizer**

### **torch.nn.Module**
딥러닝을 구성하는 Layer의 base class   
- Input, Ouput, Forward, Backward, 학습 대상이 되는 parameter(tensor) 정의

<br>

### **nn.Parameter**

Tensor 객체의 상속 객체
- nn.Module 내에 attribute가 될 때는 ‘required_grad=True’로 지정되어 AutoGrad의 대상이 됨
- 우리는 이미 있는 레이어를 사용하는 경우가 많기 때문에 직접 선정할 일은 거의 X → 대부분의 layer에는 weights 값들이 지정되어 있음

<br>

### **Backward**

Layer에 있는 Parameter들의 미분 수행

- Forward의 결과 값(모델의 예측값)과 실제 값간의 차이(loss)에 대해 미분 → 해당 값으로 Parameter 업데이트

```python
## 꼭 수행해야하는 단계 (in epochs)
....
optimizer.zero_grad()   # optimizer 초기화

outputs = model(inputs)   # model에 inputs을 넣어 예측 값 생성

loss = criterion(outputs, labels)  # 예측값(outputs)과 실제값(labels)을 기준으로 loss 확인
print(loss) 
loss.backward()  # loss에 대해 미분

optimizer.step()  # 파라미터 업데이트 
```

<br>

---

## **Dataset & Dataloader**

### **Dataset 클래스**

하나의 데이터에 어떻게 가져올 것인가?
- 데이터 입력 형태를 정의하는 클래스
- 데이터 입력하는 방식의 표준화
- Step
    1. `__init__()` : 초기 데이터 생성 방법 지정
    2. `__len__()` : 데이터의 전체 길이 
    3. `__getitem__()` : index 값을 주면 반환되는 데이터의 형태 (X, y)
- 생성시 유의점
    - 데이터 형태에 따라 각 함수를 다르게 정의
    - 모든 것을 데이터 생성 시점에 처리할 필요는 없음 (image의 Tensor 변환은 학습에 필요한 시점에)
    - Data set에 대한 표준화된 처리방법 제공 필요

<br>

### **DataLoader 클래스**

index를 가지고 여러개의 데이터를 한 번에 묶어서 모델에 던짐

- Data의 Batch를 생성해주는 클래스 → Tensor 변환 + Batch 처리가 메인 업무
- 학습 직전 데이터의 변환을 책임

```python
#https://pytorch.org/docs/stable/data.html

DataLoader(dataset, batch_size=1, shuffle=False, sampler=None,
           batch_sampler=None, num_workers=0, collate_fn=None,
           pin_memory=False, drop_last=False, timeout=0,
           worker_init_fn=None, *, prefetch_factor=2,
           persistent_workers=False)

# sampler : 데이터를 어떻게 뽑을지 index를 정하는 기법
# collate_fn : Variable length의 가변인자들을 다룰 때 사용
```