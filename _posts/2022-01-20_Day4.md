---
title:  "[부스트캠프 AI] Day4"
excerpt: "1주차 학습기록"

categories:
  - [Boostcamp AI]
tags:
  - [Boostcamp AI]

toc: true
toc_sticky: true
 
date: 2022-01-20
last_modified_at: 2022-01-23
---


# <b>[AI Math]</b>
## **6. 확률론 맛보기**
### **딥러닝에 확률론이 필요한 이유**   
&nbsp;딥러닝 : 확률론 기반의 기계학습 이론에 바탕
- 손실함수(loss function)들의 작동원리 → 데이터 공간을 통계적으로 해석해서 유도
- 분산 및 불확실성을 최소화하기 위해서는 측정하는 방법을 알아야함 
⇒ 측정 방법을 통계학에서 제공

> 💡 기계학습의 기본 원리 : 예측이 틀릴 위험을 최소화하도록 데이터를 학습하는 원리
> 1) 회귀분석의 손실함수 L2-노름
   → **예측오차의 분산을 가장 최소화**하는 방향으로 학습하도록 유도
> 2) 분류 문제의 교차엔트로피(cross-entropy)
   → **모델 예측의 불확실성을 최소화**하는 방향으로 학습하도록 유도   

&nbsp;
### **확률분포는 데이터의 초상화**
&nbsp;데이터 공간을 $x$ x $y$라 표기하고 $D$는 데이터 공간에서 데이터를 추출하는 분포

> 💡 *실제 데이터만을 가지고 $D$를 아는 것은 불가능 → 기계학습 모형을 가지고 $D$를 추론*

<!-- ![스크린샷 2022-01-20 오후 2.38.51.png](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/c1446cd5-2631-4a37-8301-44223750cdf4/스크린샷_2022-01-20_오후_2.38.51.png) -->

- $(x, y) \in x$ x $y$ 는 데이터 공간 상의 관측 가능한 데이터에 해당
- 데이터는 확률변수로 $(x, y) \sim D$라 표기   
&nbsp;
### **확률변수**
확률분포 $D$의 종류에 따라 이산형(discrete), 연속형(continuous)확률변수로 구분
- 이산확률변수    
    : 확률 변수가 가질 수 있는 경우의 수를 모두 고려하여 확률을 더해서 모델링
    
    $$\mathbb{P} (X\in A) = \sum_{x\in A} P(X = \mathbf x)$$
- 연속형확률변수   
    : 데이터 공간에 정의된 확률변수의 밀도(density)위에서의 적분을 통해 모델링
    
    $$\mathbb{P} (X\in A) = \int_{A} P(X)\mathbf {dx}$$
    
    **밀도는 누적확률분포의 변화율을 모델링하며, 확률로 해석하면 안됨*

- 결합분포(joint destribution)
    - 원래 확률 분포에 상관없이 결합분포 사용 가능 (모델링 방법에 따라 달라짐)
    - 주변확률분포 $P(\mathbf x)$ → 결합분포 $P(\mathbf x, y)$에서 유도 가능 
    **y에 대한 정보를 주지는 않음*   
&nbsp;
### **조건부확률**
 입력변수 $\mathbf x$에 대해 정답이 $y$일 확률 (연속확률분포의 경우 확률이 아닌 밀도로 해석)

- 선형모델과 소프트맥스 함수의 결합 → 데이터에서 추출된 패턴을 기반으로 확률을 해석하는데 사용

> 💡 분류문제에서 $softmax (W\phi+\mathbf b)$   
&nbsp; : 데이터 $\mathbf x$로부터 추출된 특징패턴 $\phi (\mathbf x)$과 가중치행렬 $W$을 통해 조건부확률 $P (y|\mathbf x)$ 계산   

> 회귀문제   
&nbsp; : 조건부 기대값 $\mathbb E[y|\mathbf x]$ 추정   
&nbsp;&nbsp;  -&nbsp;*조건부 기대값은 $\mathbb E || y-f(x)||_2$를 최소화하는 함수 $f(x)$와 일치*    

&nbsp;
### **기대값**
 데이터를 대표하는 통계량
- 확률분포를 통해 다른 통계적 범함수 계산에 사용
- 확률 분포가 주어지면 데이터를 분석하는데 사용 가능한 여러 통계적 범함수(statistical functional)를 계산 가능
- 분산, 첨도, 공분산 등 계산 가능

### **몬테카를로 샘플링**
- 확률분포를 모를 때 데이터를 이용하여 기대값을 계산하려면 몬테카를로 샘플링 방법 사용
- 독립추출만 보장된다면 대수의 법칙(law of large number)에 의해 수렴성 보장
- 방법    
    1) 타겟 $f(x)$에서 $x$자리에 샘플링한 데이터 대입   
    2) 데이터들에 따라서 $f(x)$의 산술평균 계산 (원하는 기대값에 근사)   
  ❗️ 독립추출 - 샘플링하는 분포에서 독립적으로 샘플링 해주어야함   
&nbsp;
### **기대값, 분산의 계산**
- 이산균등분포의 기대값

    $$\mathbb E_{x\sim P(X)}[f(\mathbf x)] = \sum _{\mathbf x \in X} f(\mathbf x)P(\mathbf x)$$
    
> 💡 $X \in \{1, 2, 3, 4\}$ 인 경우, $X$의 기대값?    
&nbsp;  ⇒   $1 * (1/4) + 2 * (1/4) + 3 * (1/4) + 4 * (1/4)$ = 2.5

&nbsp;
- 이산균등분포의 분산    
    $$V(\mathbf x) = \mathbb E [X^2] - \mathbb E [X]^2$$
    
> 💡 $X \in \{1, 2, 3, 4\}$ 인 경우, $X$의 분산?   
⇒ $1^2 * (1/4) + 2^2 * (1/4) + 3^2 * (1/4) + 4^2 * (1/4)$ - $(2.5)^2$ = 1.25   

<br></br>
## **7. 통계학 맛보기**
### **모수(parameter)**
 정규분포로 확률분포를 모델링할 경우 → 모수 : 평균, 분산

>💡 통계적 모델링의 목표
 : 적절한 가정 위에서 확률분포를 추정(inference)하는 것   
   *기계학습, 통계학이 공통적으로 추구하는 목표*

- 예측 모형의 목적   
: 데이터와 추정 방법의 불확실성을 고려, 위험을 최소화
- 유한한 개수의 데이터 관찰로 모집단의 분포를 정확하게 알기는 불가능   
 ⇒ 근사적으로 확률분포 추정

1. 모수적(parametric)방법론
  : 데이터가 특정 확률분포를 따른다고 가정한 후 그 분포를 결정하는 모수를 추정하는 방법    
2. 비모수(nonparametric)방법론
  : 특정 확률분포를 가정하지 않고 데이터에 따라 모델의 구조 및 모수의 개수가 유연하게 바뀌는 방법   
     **모수가 없다X, 쓰지 않는다X*   
&nbsp;    
### **확률분포 가정하기**
&nbsp; 히스토그램을 통해 모양을 관찰
1. 베르누이 분포 : 데이터가 2개의 값(0 또는1)만 가지는 경우
2. 카테고리 분포 : 데이터가 n개의 이산적인 값을 가지는 경우
3. 베타분포 : 데이터가 [0, 1] 사이에서 값을 가지는 경우
4. 감마분포, 로그분포 등 : 데이터가 0이상의 값을 가지는 경우
5. 정규분포, 라플라스분포 등 : 데이터가 $\mathbb R$ 전체에서 값을 가지는 경우

&nbsp;&nbsp;&nbsp; ❗️기계적으로 가정X, 데이터를 생성하는 원리는 먼저 고려

&nbsp;&nbsp;&nbsp; ❗️모수를 추정한 후에 반드시 검정   

&nbsp;
### **데이터로 모수 추정하기**
 데이터의 확률분포를 가정했다면 모수 추정 가능
- 정규분포의 모수 : 평균 $\mu$과 분산 $\sigma^2$

> 💡 표본분산을 구할 때 N이 아니라 N-1로 나누는 이유   
 : 불편(unbiased) 추정량을 구하기 위해

> 💡 중심극한정리(Central Limit Theorem)   
 : 표본평균의 표집분포는 N이 커질수록 정규분포 $N(\mu, \sigma^2 / N)$를 따름   
  **표집분포(표본평균의 확률분포) ≠ 표본분포*

&nbsp;
### **최대가능도 추정법(maximum likelihood estimation, MLE)**
&nbsp; : 이론적으로 가장 가능성이 높은 모수를 추정하는 방법 중 하나
- 데이터 집합 $\mathbf X$가 독립적으로 추출되었을 경우 로그가능도를 최적화

>💡 Why 로그 가능도 사용?   
  데이터가 많아진다면 컴퓨터의 정확도로 가능도를 계산하는 것이 불가능(오차 때문)   
> - 로그함수의 성질 : 곱을 덧셈으로 바꾸어줌 ⇒ 컴퓨터로 연산 가능
> - 연산량 $O(n^2)$ → $O (n)$
> - 대게의 손실함수의 경우 경사하강법 사용 ⇒ 음의 로그가능도 최적화  

&nbsp;
### **딥러닝에서 최대가능도 추정법**
&nbsp;  최대가능도 추정법을 이용하여 기계학습 모델 학습 가능
- 딥러닝 모델의 가중치를 $\theta = (\mathbf W^{(1)} , ..., \mathbf W^{(L)})$라 표기했을 때 분류문제에서 소프트맥스 벡터는 카테고리분포의 모수 $(p_1, ..., p_k)$를 모델링
- One-hot 벡터로 표현한 정답레이블을 관찰데이터로 이용 → 확률분포인 소프트맥스 벡터의 로그 가능도 최적화 가능   
&nbsp;
### **확률분포의 거리**
&nbsp;  기계학습에서 손실함수 → 모델이 학습하는 확률분포 - 데이터에서 관찰되는 확률분포의 거리를 통해 유도
- 두 확률분포 사이의 거리(distance) 계산
    - 총 변동 거리(Total Variation Distance, TV)
    - 쿨백-라이블러 발산(Kullback-Leibler Divergence, KL)
        - 분류문제에서 정답레이블을 $P$, 모델 예측을 $Q$라 두는 경우 
        : 최대 가능도 추정법 = 쿨백-라이블러 발산 최소화
    - 바슈타인 거리(Wasserstein Distance)   
<br></br>
## **8. 베이즈 통계학 맛보기**
&nbsp; **베이즈 정리**  : 데이터가 새로 추가되었을 때 정보를 업데이트하는 방식에 대한 기반이 됨   
&nbsp; 
### **조건부 확률**
&nbsp; 조건부확률 $P(A|B)$ : 사건 $B$가 일어난 상황에서 사건 $A$가 발생할 확률
$$P(A \cap B) = P(B)P(A|B)$$
> 💡 A라는 새로운 정보가 주어졌을 때 $P(B)$로 부터 $P(B|A)$를 계산하는 방법    
$P(B|A) =$ $P(A\cap B)\over P(A)$ $= P(B)$ ${P(A|B)}\over P(A)$   

&nbsp; 
### **베이즈 정리**
<img width="579" alt="스크린샷 2022-01-21 오전 12 47 22" src="https://user-images.githubusercontent.com/81269342/150668198-a80d1a5e-a9a7-411a-80ce-548bc8571658.png"  width="50%" height="50%">   
<!-- ![스크린샷 2022-01-21 오전 12.47.22.png](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/e5cf5114-5daf-4967-b3ea-8af780c85bef/스크린샷_2022-01-21_오전_12.47.22.png) -->

<!-- ### 조건부 확률의 시각화

![스크린샷 2022-01-21 오전 12.48.12.png](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/4a4ff7d8-2e9a-45af-8d90-4b25f26ef5b4/스크린샷_2022-01-21_오전_12.48.12.png)

- 오차행렬 (정밀도, 재현율, f1-score)
    
    ❗️위의 예시와 행렬이 전치된 상태니 이해에 주의
    
    <!-- ![흐름 6-3-1.png](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/83c3f25c-0932-476f-a500-f72631b096bc/흐름_6-3-1.png)
    
    ![흐름 6-4-1.png](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/d4a4a83b-2ef1-497f-9093-297dcd39026d/흐름_6-4-1.png)
    
    ![흐름 6-5-1.png](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/cedeae3b-d0fd-4f01-a827-428a0d06b099/흐름_6-5-1.png) --> 
    
&nbsp; 
### **조건부 확률과 인과관계**
&nbsp;  조건부 확률을 인과관계(causality)를 추론할 때 함부로 사용X
- 인과관계   
 : 데이터 분포의 변화에 강건한 예측 모형을 만들 때 필요
  - 중첩요인(confounding factor)의 효과를 제거, 원인에 해당하는 변수만의 인과관계 계산 필요
  > **효과 제거하지 않으면 가짜 연관성(spurious correlation)이 나옴*

<br></br>
## **9. CNN 첫걸음**
### **Convolution 연산 이해하기**
 MLP → 각 뉴런들이 선형모델과 활성함수로 모두 연결된(fully connected) 구조
- 커널(kernel)을 입력벡터 상에서 움직여가면서 선형모델과 합성함수가 적용되는 구조

**[수식비교]**
<table>
  <tr>
    <td><img alt="스크린샷 2022-01-21 오전 12 58 31" src="https://user-images.githubusercontent.com/81269342/150668378-5bff0f59-d07c-47bd-807e-66406ad14881.png"/></td><td><img alt="스크린샷 2022-01-21 오전 12 59 18" src="https://user-images.githubusercontent.com/81269342/150668386-96cf2045-8be8-4af6-bfd6-012f39ea58f5.png"/></td>
  <tr>
  <td>→ MLP </td><td>→ Convolution 연산</td> 
</table>
 
&nbsp;


**[그림비교]**
<table>
  <tr>
    <td><img alt="스크린샷 2022-01-21 오전 1 02 37" src="https://user-images.githubusercontent.com/81269342/150668556-94bdb2e8-42db-48ef-baeb-2f9634c54274.png"/></td><td><img alt="스크린샷 2022-01-21 오전 1 02 59" src="https://user-images.githubusercontent.com/81269342/150668562-125b1a2a-7cee-4e0a-a978-24775d7b0da2.png"/></td>
  <tr>
  <td>→ MLP   

  각 성분 $h_i$ 에 대응하는 가중치 행 $W_i$ 필요   
     

 </td><td>→ Convolution 연산   

   모든 $i$에 대해 적용되는 커널은 $V$로 같고, 커널의 사이즈만큼 $\mathbf x$상에서 이동하면서 적용</td> 
</table>


- Convolution 연산의 수학적인 의미   
&nbsp; : 신호(signal)를 커널을 이용해 국소적으로 증폭 또는 감소시켜 정보를 추출 또는 필터링하는 것
- 커널은 정의역 내에서 움직여도 변하지X, 주어진 신호에 국소적(local)으로 적용
- Convolution 연산은 1차원뿐만 아니라 다양한 차원에서 가능

> &nbsp;💡 $i, j, k$가 바뀌어도 커널 $f$의 값은 바뀌지 X   

&nbsp;
### **2차원 Convolution 연산**
&nbsp; 2D-Conv 연산은 커널(kernel)을 입력벡터 상에서 움직여가며 선형모델과 합성 함수가 적용되는 구조

<img width="931" alt="스크린샷 2022-01-21 오전 1 11 10" src="https://user-images.githubusercontent.com/81269342/150668663-054c5af7-2976-4097-9b96-537e8ea02112.png">   

&nbsp;   
> 💡 출력 크기의 계산   
&nbsp; 입력 크기 $(H, W)$, 커널 크기 $(K_H, K_W)$, 출력 크기 $(O_H, O_W)$ 일 때,   
&nbsp;  👉  $O_H = H - K_H + 1$  , $O_W = W - K_W +1$

- 채널이 여러개인 경우 커널의 채널 수와 입력의 채널 수가 같아야함
- 3차원부터는 행렬이 아니라 ‘텐서’라고 부름   
&nbsp;
### **Convolution 연산의 역전파**
<table>
  <tr>
    <td><img alt="스크린샷 2022-01-21 오전 1 15 54" src="https://user-images.githubusercontent.com/81269342/150668673-b1196d30-8b35-4e04-b234-cc8770cf4641.png"/></td><td><img alt="스크린샷 2022-01-21 오전 1 17 28" src="https://user-images.githubusercontent.com/81269342/150668698-4ffbec89-c62b-4c38-8573-0ab9897053fd.png"></td>
  <tr>
</table>



- Convolution 연산은 역전파 계산시에도 Convolution 연산이 나옴
 → 커널이 모든 입력데이터에 공통으로 적용되기 때문
- 역전파 단계에서 다시 커널을 통해 gradient가 전달 
→ $\delta_1w_3 + \delta_2w_2 + \delta_3W_1$
- 커널에는 $\delta$(미분값)에 입력값 $x_3$을 곱해서 전달
- 각 커널에 들어오는 모든 gradient를 더하면 결국 convolution 연산과 같음   

<p align="center">
<img width="200" alt="스크린샷 2022-01-21 오전 1 26 02" src="https://user-images.githubusercontent.com/81269342/150668795-925631b6-c1ae-465d-8c43-33137bbf5799.png" >
</p>