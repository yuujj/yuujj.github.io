---
layout : post
title:  "[부스트캠프 AI] Day9, 10"
excerpt: "2주차 학습기록"

categories: ["Boostcamp AI", "Python", "PyTorch"]
tags: ["Boostcamp AI"]

published: true
toc: true
toc_sticky: true
 
date: 2022-01-28
last_modified_at: 2022-01-30
use_math: true
---

# <b>[PyTorch]</b>
---

## **Multi-GPU 학습**

### **Model parallel**

- 다중 GPU에 학습을 분산하는 두 가지 방법
    - 모델 나누기 - 이전부터 사용(alexnet)
        - 모델의 병목, 파이프라인의 어려움 → 모델 병렬화는 고난이도 과제
- 파이프라인 구축 - 순차적으로가 아닌 병렬적으로 수행되도록 구축 필요

<br>

### **Data parallel**

- 데이터를 나눠 GPU에 할당 후 결과의 평균을 취하는 방법
- minibatch 수식과 유사, 한번에 여러 GPU에서 수행
- in PyTorch
    - DataParallel - 단순히 데이터를 분배한 후 평균을 취함
        
        → GPU 사용 불균형 문제 발생, Batch size 감소, GIL
        
    - DistributedDataParallel - 각 CPU마다 process 생성하여 개별 GPU에 할당
        
        → 기본적으로 DataParallel로 하나 개별적으로 연산의 평균을 냄
        
        
        > 💡 pin_memory : DRAM 메모리에 데이터를 바로바로 올릴 수 있도록 절차를 간소하게 데이터를 저장하는 방식
        > - DataLoader에서 True로 바꾸면 Tensor를 CUDA 고정 메모리에 할당   
         :  고정된 메모리에서 데이터를 가져오기 때문에 데이터 전송이 훨씬 빨라짐
        
 <br>
       
---

## **Hyperparameter Tuning**

모델 스스로 학습하지 않는 값은 사람이 지정 (learning rate, Model size, optimizer, ..)

- 모델의 성능 개선 방법
    1. 모델 바꾸기 (이익이 그리 크지 않음-유명한 모델들이 있기 때문)
    2. 데이터+ 
    3. Hyperparameter Tuning
- 방법
    - grid search : 일정한 방법으로 자름 (로그를 취해서 값을 올려주는 경우 많음)
    - random search
    - 최근에는 베이지안 기법들이 주도 (BOHB, 2018)
- Ray (도구) - TensorboardX 사용
    - multi-node multi processing 지원 모듈
    - ML/DL 병렬 처리를 위해 개발된 모듈로, 현재의 분산병렬 ML/DL 모듈의 표준
    - Hyperparameter Search를 위한 다양한 모듈 제공
    
<br>

---

## **PyTorch**

### **torchvision.transforms**

- Resize()
- RandomCrop(), CenterCrop()
- RandomRotation()
- RandomHorizontalFlip(), RandomVerticalFlip()
- library - albumentations

<br>

### **Encoder & Decoder**

- encoder(인코더) : 입력 데이터를 인코딩(부호화) - 입력 처리
- decoder(디코더) : 인코딩된 데이터를 디코딩(복호화) - 결과 생성

```python
## make vocab dict
tokenizer = torchtext.data.utils.get_tokenizer('basic_english')
counter = collections.Counter()

for line in lines:
	token = tokenizer(line)
	counter.update(token)

vocab = torchtext.vocab.vocab(counter, min_freq=1)

# encoder1
encoder = vocab.get_stoi()

# encoder2
def encode(x):
	return [vocab.get_stoi()[s] for n, s in enumerate(tokenizer(x))]

# decoder1
decoder = vocab.get_itos()

# decoder2
def decode(x):
	return [vocab.get_itos()[i] for n, i in enumerate(x)]
```

<br>

---
## **PyTorch Troubleshooting**

### **OOM이 해결 어려운 이유**

- 발생 이유&원인 파악의 어려움
- 메모리 이전 상황의 파악이 어려움
- 해결 시도 : Batch size ↓ → GPU clean → Run

<br>

### **GPUUtil**

- nvidia-smi처럼 GPU의 상태를 보여주는 모듈
- iter마다 메모리가 늘어나는지 확인!!

<br>

### **torch.cuda.empty_cache()**

- 사용되지 않은 GPU상 cache를 정리
- 가용 메모리 확보

<br>

### **loop**

- python 특성상 loop가 끝나도 메모리 공간 차지
- training loop tensor로 축적 되는 변수 확인 필요
- 1-d tensor의 경우 python 기본 객체로 변환하여 처리 필요.
- del로 필요 없어진 변수 삭제