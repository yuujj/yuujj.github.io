---
layout : post
title:  "[ë¶€ìŠ¤íŠ¸ìº í”„ AI] Day9, 10"
excerpt: "2ì£¼ì°¨ í•™ìŠµê¸°ë¡"

categories: ["Boostcamp AI", "Python", "PyTorch"]
tags: ["Boostcamp AI"]

published: true
toc: true
toc_sticky: true
 
date: 2022-01-28
last_modified_at: 2022-01-30
use_math: true
---

# <b>[PyTorch]</b>
---

## **Multi-GPU í•™ìŠµ**

### **Model parallel**

- ë‹¤ì¤‘ GPUì— í•™ìŠµì„ ë¶„ì‚°í•˜ëŠ” ë‘ ê°€ì§€ ë°©ë²•
    - ëª¨ë¸ ë‚˜ëˆ„ê¸° - ì´ì „ë¶€í„° ì‚¬ìš©(alexnet)
        - ëª¨ë¸ì˜ ë³‘ëª©, íŒŒì´í”„ë¼ì¸ì˜ ì–´ë ¤ì›€ â†’ ëª¨ë¸ ë³‘ë ¬í™”ëŠ” ê³ ë‚œì´ë„ ê³¼ì œ
- íŒŒì´í”„ë¼ì¸ êµ¬ì¶• - ìˆœì°¨ì ìœ¼ë¡œê°€ ì•„ë‹Œ ë³‘ë ¬ì ìœ¼ë¡œ ìˆ˜í–‰ë˜ë„ë¡ êµ¬ì¶• í•„ìš”

<br>

### **Data parallel**

- ë°ì´í„°ë¥¼ ë‚˜ëˆ  GPUì— í• ë‹¹ í›„ ê²°ê³¼ì˜ í‰ê· ì„ ì·¨í•˜ëŠ” ë°©ë²•
- minibatch ìˆ˜ì‹ê³¼ ìœ ì‚¬, í•œë²ˆì— ì—¬ëŸ¬ GPUì—ì„œ ìˆ˜í–‰
- in PyTorch
    - DataParallel - ë‹¨ìˆœíˆ ë°ì´í„°ë¥¼ ë¶„ë°°í•œ í›„ í‰ê· ì„ ì·¨í•¨
        
        â†’ GPU ì‚¬ìš© ë¶ˆê· í˜• ë¬¸ì œ ë°œìƒ, Batch size ê°ì†Œ, GIL
        
    - DistributedDataParallel - ê° CPUë§ˆë‹¤ process ìƒì„±í•˜ì—¬ ê°œë³„ GPUì— í• ë‹¹
        
        â†’ ê¸°ë³¸ì ìœ¼ë¡œ DataParallelë¡œ í•˜ë‚˜ ê°œë³„ì ìœ¼ë¡œ ì—°ì‚°ì˜ í‰ê· ì„ ëƒ„
        
        
        > ğŸ’¡ pin_memory : DRAM ë©”ëª¨ë¦¬ì— ë°ì´í„°ë¥¼ ë°”ë¡œë°”ë¡œ ì˜¬ë¦´ ìˆ˜ ìˆë„ë¡ ì ˆì°¨ë¥¼ ê°„ì†Œí•˜ê²Œ ë°ì´í„°ë¥¼ ì €ì¥í•˜ëŠ” ë°©ì‹
        > - DataLoaderì—ì„œ Trueë¡œ ë°”ê¾¸ë©´ Tensorë¥¼ CUDA ê³ ì • ë©”ëª¨ë¦¬ì— í• ë‹¹   
         :  ê³ ì •ëœ ë©”ëª¨ë¦¬ì—ì„œ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ê¸° ë•Œë¬¸ì— ë°ì´í„° ì „ì†¡ì´ í›¨ì”¬ ë¹¨ë¼ì§
        
 <br>
       
---

## **Hyperparameter Tuning**

ëª¨ë¸ ìŠ¤ìŠ¤ë¡œ í•™ìŠµí•˜ì§€ ì•ŠëŠ” ê°’ì€ ì‚¬ëŒì´ ì§€ì • (learning rate, Model size, optimizer, ..)

- ëª¨ë¸ì˜ ì„±ëŠ¥ ê°œì„  ë°©ë²•
    1. ëª¨ë¸ ë°”ê¾¸ê¸° (ì´ìµì´ ê·¸ë¦¬ í¬ì§€ ì•ŠìŒ-ìœ ëª…í•œ ëª¨ë¸ë“¤ì´ ìˆê¸° ë•Œë¬¸)
    2. ë°ì´í„°+ 
    3. Hyperparameter Tuning
- ë°©ë²•
    - grid search : ì¼ì •í•œ ë°©ë²•ìœ¼ë¡œ ìë¦„ (ë¡œê·¸ë¥¼ ì·¨í•´ì„œ ê°’ì„ ì˜¬ë ¤ì£¼ëŠ” ê²½ìš° ë§ìŒ)
    - random search
    - ìµœê·¼ì—ëŠ” ë² ì´ì§€ì•ˆ ê¸°ë²•ë“¤ì´ ì£¼ë„ (BOHB, 2018)
- Ray (ë„êµ¬) - TensorboardX ì‚¬ìš©
    - multi-node multi processing ì§€ì› ëª¨ë“ˆ
    - ML/DL ë³‘ë ¬ ì²˜ë¦¬ë¥¼ ìœ„í•´ ê°œë°œëœ ëª¨ë“ˆë¡œ, í˜„ì¬ì˜ ë¶„ì‚°ë³‘ë ¬ ML/DL ëª¨ë“ˆì˜ í‘œì¤€
    - Hyperparameter Searchë¥¼ ìœ„í•œ ë‹¤ì–‘í•œ ëª¨ë“ˆ ì œê³µ
    
<br>

---

## **PyTorch**

### **torchvision.transforms**

- Resize()
- RandomCrop(), CenterCrop()
- RandomRotation()
- RandomHorizontalFlip(), RandomVerticalFlip()
- library - albumentations

<br>

### **Encoder & Decoder**

- encoder(ì¸ì½”ë”) : ì…ë ¥ ë°ì´í„°ë¥¼ ì¸ì½”ë”©(ë¶€í˜¸í™”) - ì…ë ¥ ì²˜ë¦¬
- decoder(ë””ì½”ë”) : ì¸ì½”ë”©ëœ ë°ì´í„°ë¥¼ ë””ì½”ë”©(ë³µí˜¸í™”) - ê²°ê³¼ ìƒì„±

```python
## make vocab dict
tokenizer = torchtext.data.utils.get_tokenizer('basic_english')
counter = collections.Counter()

for line in lines:
	token = tokenizer(line)
	counter.update(token)

vocab = torchtext.vocab.vocab(counter, min_freq=1)

# encoder1
encoder = vocab.get_stoi()

# encoder2
def encode(x):
	return [vocab.get_stoi()[s] for n, s in enumerate(tokenizer(x))]

# decoder1
decoder = vocab.get_itos()

# decoder2
def decode(x):
	return [vocab.get_itos()[i] for n, i in enumerate(x)]
```

<br>

---
## **PyTorch Troubleshooting**

### **OOMì´ í•´ê²° ì–´ë ¤ìš´ ì´ìœ **

- ë°œìƒ ì´ìœ &ì›ì¸ íŒŒì•…ì˜ ì–´ë ¤ì›€
- ë©”ëª¨ë¦¬ ì´ì „ ìƒí™©ì˜ íŒŒì•…ì´ ì–´ë ¤ì›€
- í•´ê²° ì‹œë„ : Batch size â†“ â†’ GPU clean â†’ Run

<br>

### **GPUUtil**

- nvidia-smiì²˜ëŸ¼ GPUì˜ ìƒíƒœë¥¼ ë³´ì—¬ì£¼ëŠ” ëª¨ë“ˆ
- iterë§ˆë‹¤ ë©”ëª¨ë¦¬ê°€ ëŠ˜ì–´ë‚˜ëŠ”ì§€ í™•ì¸!!

<br>

### **torch.cuda.empty_cache()**

- ì‚¬ìš©ë˜ì§€ ì•Šì€ GPUìƒ cacheë¥¼ ì •ë¦¬
- ê°€ìš© ë©”ëª¨ë¦¬ í™•ë³´

<br>

### **loop**

- python íŠ¹ì„±ìƒ loopê°€ ëë‚˜ë„ ë©”ëª¨ë¦¬ ê³µê°„ ì°¨ì§€
- training loop tensorë¡œ ì¶•ì  ë˜ëŠ” ë³€ìˆ˜ í™•ì¸ í•„ìš”
- 1-d tensorì˜ ê²½ìš° python ê¸°ë³¸ ê°ì²´ë¡œ ë³€í™˜í•˜ì—¬ ì²˜ë¦¬ í•„ìš”.
- delë¡œ í•„ìš” ì—†ì–´ì§„ ë³€ìˆ˜ ì‚­ì œ